# -*- coding: utf-8 -*-
"""pretrained_mbart_ru_for_job_description.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19fkRDq8OOXAAklqpkBTFXb53UydUP0bH
"""

!pip install transformers sentencepiece

from transformers import MBartTokenizer, MBartForConditionalGeneration

model_name = "IlyaGusev/mbart_ru_sum_gazeta"
tokenizer = MBartTokenizer.from_pretrained(model_name)

model = MBartForConditionalGeneration.from_pretrained(model_name)
model.to("cuda")

import pandas as pd

df = pd.read_excel('/content/resume_128k.xlsx')
df.head()

df.columns

from tqdm import tqdm
tqdm.pandas()

def summurizer(article_text):
  article_text = str(article_text)
  input_ids = tokenizer(
      [article_text],
      max_length=600,
      truncation=True,
      return_tensors="pt",
  )["input_ids"].to("cuda")

  output_ids = model.generate(input_ids=input_ids, no_repeat_ngram_size=4)[0]
  summary = tokenizer.decode(output_ids, skip_special_tokens=True)
  return summary

df['Description_short'] = df.progress_apply(lambda x: summurizer(x['Description']), axis = 1)
df

df.to_excel('with_short_description')

from tqdm import tqdm
tqdm.pandas()

def summurizer(article_text):
  article_text = str(article_text)
  input_ids = tokenizer(
      [article_text],
      max_length=600,
      truncation=True,
      return_tensors="pt",
  )["input_ids"].to("cuda")

  output_ids = model.generate(input_ids=input_ids, no_repeat_ngram_size=4)[0]
  summary = tokenizer.decode(output_ids, skip_special_tokens=True)
  return summary

test_df = df.head(60)
test_df['Description_short'] = test_df.progress_apply(lambda x: summurizer(x['Description']), axis = 1)
test_df